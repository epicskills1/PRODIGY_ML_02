# -*- coding: utf-8 -*-
"""CustomerSegmentationusingKMeansClustering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q5s21aSj3ftI_1bdfgSJpXUnbq8wK_yt

Importing Dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, adjusted_rand_score
from sklearn.model_selection import train_test_split

"""Loading and Exploring the Dataset

"""

# Load the data from CSV file into a DataFrame
customer_data = pd.read_csv('/content/Mall_Customers.csv')

# Display the first 5 rows
print(customer_data.head())

# Checking the shape of the dataset
print("Dataset Shape:", customer_data.shape)

# Getting information about the dataset
customer_data.info()

# Checking for missing values
print("Missing Values:\n", customer_data.isnull().sum())

"""Selecting Features for Clustering"""

# Select 'Annual Income' and 'Spending Score' as features
X = customer_data.iloc[:, [3, 4]].values

print("Selected Features:\n", X)

"""Data Scaling"""

# Scale the data using StandardScaler to standardize feature values
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print(X_scaled[:5])  # Display the first 5 rows of scaled data

"""Determining the Optimal Number of Clusters using Elbow Method"""

# Calculate WCSS (Within-Cluster Sum of Squares) for different numbers of clusters
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

# Plot the Elbow Graph
plt.figure(figsize=(8, 5))
plt.plot(range(1, 11), wcss, marker='o')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()

"""Apply K-Means with Optimal Clusters"""

# Applying K-Means with k=5 (optimal number of clusters from the elbow graph)
kmeans = KMeans(n_clusters=5, init='k-means++', random_state=42)
Y = kmeans.fit_predict(X_scaled)

# Display cluster labels for each data point
print(Y[:10])

""" Visualize the Clusters"""

# Plotting the clusters along with their centroids
plt.figure(figsize=(8, 8))
for i in range(5):
    plt.scatter(X_scaled[Y == i, 0], X_scaled[Y == i, 1], s=50, label=f'Cluster {i+1}')

# Plotting the centroids
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=100, c='black', marker='x', label='Centroids')

plt.title('Customer Segmentation')
plt.xlabel('Annual Income (scaled)')
plt.ylabel('Spending Score (scaled)')
plt.legend()
plt.show()

"""Evaluating the Clustering with Metrics"""

# Silhouette Score: Measures how well-separated the clusters are
silhouette = silhouette_score(X_scaled, Y)
print(f'Silhouette Score: {silhouette:.2f}')
# Adjusted Rand Index (ARI): Measures similarity to a ground-truth clustering, assumes labels are known
# For demonstration, we use the predicted labels as both inputs (ARI = 1 in this case)
ari_score = adjusted_rand_score(Y, Y)
print(f'Adjusted Rand Index (ARI): {ari_score:.2f}')